import os

from langchain_core.language_models import BaseChatModel

from .logger import logger
from .providers import get_provider


class Model:
    model = None
    provider_name = None

    @classmethod
    def initialize(cls, model=None) -> None:
        if cls.model is None:
            cls.provider_name = os.environ.get("LLM_PROVIDER", "openai").lower()

            if model is None:
                # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«åã‚’å–å¾—ï¼ˆãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã«å¿œã˜ã¦å¤‰ã‚ã‚‹ï¼‰
                if cls.provider_name == "openai":
                    model_name = os.environ.get("OPENAI_MODEL_NAME")
                    if not model_name:
                        raise ValueError("OPENAI_MODEL_NAME environment variable not set")
                elif cls.provider_name == "anthropic":
                    model_name = os.environ.get("ANTHROPIC_MODEL_NAME")
                    if not model_name:
                        raise ValueError("ANTHROPIC_MODEL_NAME environment variable not set")
                elif cls.provider_name == "gemini":
                    model_name = os.environ.get("GEMINI_MODEL_NAME")
                    if not model_name:
                        raise ValueError("GEMINI_MODEL_NAME environment variable not set")
                elif cls.provider_name == "ollama":
                    model_name = os.environ.get("OLLAMA_MODEL_NAME")
                    if not model_name:
                        raise ValueError("OLLAMA_MODEL_NAME environment variable not set")
                else:
                    raise ValueError(f"Unknown LLM provider: {cls.provider_name}")
                cls.model = model_name
            else:
                cls.model = model

            logger.info(f"ğŸ¤– ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ {cls.provider_name} ã§ãƒ¢ãƒ‡ãƒ« {cls.model} ã‚’ä½¿ç”¨")

    def __init__(self, model=None) -> None:
        if Model.model is None:
            Model.initialize(model)
        self.model = Model.model
        self.provider_name = Model.provider_name

    def llm(self) -> BaseChatModel:
        """
        ç’°å¢ƒå¤‰æ•°ã§æŒ‡å®šã•ã‚ŒãŸãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®LLMã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¿”ã™

        Returns:
            BaseChatModel: ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼å›ºæœ‰ã®Chatãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
        """
        provider = get_provider(self.model)
        return provider.get_llm()
